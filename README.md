# Deepfake_audio_recognition
"Deepfake Audio Detection using CNN, RNN, LSTM with Mel-Spectrograms"

# ğŸ™ï¸ Deepfake Audio Detection using CNN + RNN + LSTM

This project aims to detect **deepfake audio** by classifying samples into three categories:  
âœ… Real  
âŒ Fake (AI-generated)  
âš ï¸ Hybrid (a mix of real and fake audio)

---

## ğŸ”§ Technologies Used

- **Python**
- **TensorFlow / Keras**
- **CNN + RNN + LSTM**
- **Mel-Spectrogram (feature extraction)**
- **Librosa, NumPy, Pydub**
- **Focal Loss for imbalanced data**

---

## ğŸ§  Model Architecture

> A hybrid architecture using:
- **CNN layers** to learn spatial features from Mel-spectrograms
- **RNN + LSTM layers** for temporal sequence modeling
- **Softmax** output for multi-class classification (Real / Fake / Hybrid)

---

## ğŸ“ Dataset

- Collected real audio and fake (TTS/AI-generated) samples
- Hybrid audio created using **Pydub** to combine real and fake clips
- Converted all samples to Mel-Spectrograms for input into the model

---

## ğŸ‹ï¸â€â™‚ï¸ Training

- Applied **focal loss** to reduce the impact of class imbalance
- Used **ModelCheckpoint** to save the best model
- Trained with **batch normalization**, **dropout**, and **Adam optimizer**

---

## ğŸ“Š Results

- Achieved high precision on unseen samples
- Effective in distinguishing subtle manipulations in hybrid audio
- Suitable for applications in **security**, **authentication**, and **media verification**

---

## â–¶ï¸ How to Run

ğŸ“Œ Prerequisites
Anaconda (installed)

Python 3.7 or higher (comes with Anaconda)

Required libraries: TensorFlow, Keras, NumPy, Librosa, Pydub, Matplotlib, etc.

ğŸš€ Step-by-Step Instructions
1ï¸âƒ£ Open Anaconda Prompt
Go to Start Menu â†’ search and open Anaconda Prompt.

2ï¸âƒ£ Navigate to the Project Directory
Type the path where your project is located. Example:

cd D:\ML_Projects\Deepfake_audio_recognition
3ï¸âƒ£ Create a Virtual Environment (Optional but Recommended)

conda create -n deepfake_env python=3.8
conda activate deepfake_env

4ï¸âƒ£ Install Required Libraries
Use pip or conda inside Anaconda Prompt:
pip install -r requirements.txt
If there's no requirements.txt, install manually:

pip install tensorflow keras numpy matplotlib librosa pydub scikit-learn

5ï¸âƒ£ Run the Project
1st step:
python CNNRNNLSTM.py(for training the model)
2nd step:
python script.py(for testing real time audio)

6ï¸âƒ£ (Optional) View Outputs
Spectrograms / Plots will open in a window or be saved to a folder like outputs/

Accuracy, loss, and model performance will print in the console

ğŸ“‚ Dataset Location
Make sure the audio dataset is placed in a folder like ./data/ or update the script to point to the correct location.
(Should me taken from kaggle)



## ğŸ“¸ Sample Mel-Spectrogram

![Mel Spectrogram Example](images/mel_spectrogram_sample.png)

---

## ğŸ‘¨â€ğŸ’» Author

**Shivam Yadav**  
[LinkedIn](https://www.linkedin.com/in/shivam-yadav-3238a5229)  
Email: shivamyadav22sep@gmail.com

---

## ğŸ“„ License

This project is open-source for educational and research purposes.


